{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"SubtaskA_EvaluationData.csv\"\n",
    "out_path = \"bhuvnesh_gupta.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sent_list):\n",
    "\n",
    "    keywords = [\"suggest\",\"recommend\",\"hopefully\",\"go for\",\"request\",\"it would be nice\",\"adding\",\"should come with\",\"should be able\",\"could come with\", \"i need\" , \"we need\",\"needs\", \"would like to\",\"would love to\",\"allow\",\"add\"]\n",
    "\n",
    "    # Goldberg et al.\n",
    "    pattern_strings = [r'.*would\\slike.*if.*', r'.*i\\swish.*', r'.*i\\shope.*', r'.*i\\swant.*', r'.*hopefully.*',\n",
    "                       r\".*if\\sonly.*\", r\".*would\\sbe\\sbetter\\sif.*\", r\".*should.*\", r\".*would\\sthat.*\",\n",
    "                       r\".*can't\\sbelieve.*didn't.*\", r\".*don't\\sbelieve.*didn't.*\", r\".*do\\swant.*\", r\".*i\\scan\\shas.*\"]\n",
    "    compiled_patterns = []\n",
    "    for patt in pattern_strings:\n",
    "        compiled_patterns.append(re.compile(patt))\n",
    "\n",
    "\n",
    "    label_list = []\n",
    "    for sent in sent_list:\n",
    "        tokenized_sent = word_tokenize(sent[1])\n",
    "        tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "        tags = [i[1] for i in tagged_sent]\n",
    "        label = 0\n",
    "        patt_matched = False\n",
    "        for compiled_patt in compiled_patterns:\n",
    "            joined_sent = \" \".join(tokenized_sent)\n",
    "            matches = compiled_patt.findall(joined_sent)\n",
    "            if len(matches) > 0:\n",
    "                patt_matched = True\n",
    "        keyword_match = any(elem in keywords for elem in tokenized_sent)\n",
    "        \n",
    "        \n",
    "        pos_match = any(elem in ['MD', 'VB'] for elem in tags)\n",
    "\n",
    "    \n",
    "\n",
    "        if patt_matched:\n",
    "            label = 1\n",
    "        elif keyword_match == True:\n",
    "                label = 1\n",
    "        elif pos_match == True:\n",
    "                label = 1    \n",
    "     \n",
    "\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    return label_list\n",
    "\n",
    "#This reads CSV a given CSV and stores the data in a list\n",
    "def read_csv(data_path):\n",
    "    file_reader = csv.reader(open(data_path,\"rt\", errors=\"ignore\",encoding=\"utf-8\"), delimiter=',')\n",
    "    sent_list = []\n",
    "\n",
    "    for row in file_reader:\n",
    "        id = row[0]\n",
    "        sent = row[1]\n",
    "        sent_list.append((id,sent))\n",
    "    return sent_list\n",
    "\n",
    "#This will create and write into a new CSV\n",
    "def write_csv(sent_list, label_list, out_path):\n",
    "        filewriter = csv.writer(open(out_path, \"w\",encoding=\"utf-8\"))\n",
    "        filewriter.writerow([\"id\",\"Sentence\",\"Prediction\"])\n",
    "        count = 0\n",
    "        data = [[id, sent, label] for ((id, sent), label) in zip(sent_list, label_list)]\n",
    "        filewriter.writerows(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9566</td>\n",
       "      <td>This would enable live traffic aware apps.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9569</td>\n",
       "      <td>Please try other formatting like bold italics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9576</td>\n",
       "      <td>Since computers were invented to save time I s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9577</td>\n",
       "      <td>Allow rearranging if the user wants to change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9579</td>\n",
       "      <td>Add SIMD instructions for better use of ARM NE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           Sentence  Prediction\n",
       "0  9566         This would enable live traffic aware apps.           1\n",
       "1  9569  Please try other formatting like bold italics ...           1\n",
       "2  9576  Since computers were invented to save time I s...           1\n",
       "3  9577  Allow rearranging if the user wants to change ...           1\n",
       "4  9579  Add SIMD instructions for better use of ARM NE...           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list = read_csv(data_path)\n",
    "label_list = classify(sent_list)\n",
    "write_csv(sent_list, label_list, out_path)\n",
    "df = pd.read_csv(out_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Sentiment Intensity Analyser To Find Out Whether The Sentence Is Positive Or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound  neg    neu    pos\n",
       "0    0.0000  0.0  1.000  0.000\n",
       "1    0.7506  0.0  0.575  0.425\n",
       "2    0.4939  0.0  0.914  0.086\n",
       "3    0.2942  0.0  0.785  0.215\n",
       "4    0.4404  0.0  0.818  0.182"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"SubtaskA_EvaluationData.csv\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid=SentimentIntensityAnalyzer()\n",
    "s=[]\n",
    "for i in range(len(df)):\n",
    "    s.append(sid.polarity_scores(str(df.Sentence[i])))\n",
    "df_2 = pd.DataFrame(s)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the sentences and then removing the stop words from them. TO find out the most occuring words in the suggestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent= []\n",
    "filtered_sentence =[]\n",
    "stop_words = set(stopwords.words('english')) \n",
    "for sent in df.Sentence:\n",
    "    tokenized_sent+=nltk.word_tokenize(sent)\n",
    "for word in tokenized_sent: \n",
    "    if word not in stop_words: \n",
    "        filtered_sentence.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".                      680\n",
       "I                      228\n",
       "app                    139\n",
       ")                      112\n",
       "(                      104\n",
       "apps                    67\n",
       "like                    65\n",
       "Windows                 64\n",
       "n't                     57\n",
       "would                   55\n",
       "'s                      53\n",
       ":                       52\n",
       "UWP                     47\n",
       "use                     46\n",
       "This                    45\n",
       "user                    45\n",
       "file                    44\n",
       "application             38\n",
       "using                   36\n",
       "It                      36\n",
       "The                     35\n",
       "one                     35\n",
       "users                   29\n",
       "support                 28\n",
       "get                     28\n",
       "API                     28\n",
       "Currently               28\n",
       "see                     27\n",
       "need                    27\n",
       "!                       26\n",
       "                      ... \n",
       "leaks                    1\n",
       "swipe-open               1\n",
       "optimized                1\n",
       "relevance                1\n",
       "Browser                  1\n",
       "AppXPackageFileList      1\n",
       "worth                    1\n",
       "job                      1\n",
       "URI                      1\n",
       "loosing                  1\n",
       "Exceptions               1\n",
       "disk                     1\n",
       "misleading               1\n",
       "manipulate               1\n",
       "finger                   1\n",
       "noise                    1\n",
       "moves                    1\n",
       "folders                  1\n",
       "terms                    1\n",
       "Expected                 1\n",
       "imposed                  1\n",
       "pleasing                 1\n",
       "customizing              1\n",
       "purchased                1\n",
       "exploit                  1\n",
       "FallbackValue            1\n",
       "differences              1\n",
       "anything                 1\n",
       "compliant                1\n",
       "starting                 1\n",
       "Name: 0, Length: 3102, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized = pd.DataFrame(filtered_sentence)\n",
    "#df_tokenized\n",
    "df_tokenized.rename(columns={'0':'words',}, \n",
    "                 inplace=True)\n",
    "df_tokenized[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
